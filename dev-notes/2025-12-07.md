# RAG Learning Notes - 2025-12-07

## Gemini API Quota Exhaustion & Rate Limiting Improvements

### Problem Statement

After running the RAG app for about a week, encountered a `ResourceExhausted` error from the Gemini API:

```
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 12.8377529s.
```

The error was silently logged as "Task exception was never retrieved" and users saw no feedback about what went wrong.

### Analysis

#### Gemini Free Tier Limits

| Metric | Approximate Limit |
|--------|-------------------|
| Requests per minute (RPM) | 10-15 |
| Tokens per minute (TPM) | 250,000 |
| Requests per day (RPD) | ~1,500 |

#### Token Consumption Per Query (Our App)

Based on code analysis of `rag_service.py` and `config.py`:

| Component | Tokens (estimated) |
|-----------|-------------------|
| System prompt template | ~200 |
| Retrieved chunks (3 × 250 tokens) | ~750 |
| Chunk headers/formatting | ~50 |
| User question | ~20-50 |
| Conversation history (6 msgs max) | ~300-600 |
| **Total Input Tokens** | **~1,300-1,650** |
| Output (response) | ~200-500 |

#### Usage Dashboard Analysis

Actual usage from Google AI Studio dashboard (28-day view):
- Peak requests: ~30/day
- Peak input tokens: ~45K/day
- Total requests over 28 days: ~100-150

This is well below the theoretical limits, suggesting the issue was **rate limiting** (requests per minute) rather than quota exhaustion.

#### Root Cause

The existing rate limiter was **per-IP** (15 req/min per user), but Gemini's free tier limit is **global** (10-15 req/min per API key). Multiple concurrent users could collectively exceed the limit even if each individual stayed under their per-IP limit.

### Cost Analysis: Paid Tier

If upgrading to a paid API key with Gemini 2.0 Flash:

| Type | Price |
|------|-------|
| Input | $0.10 per 1M tokens |
| Output | $0.40 per 1M tokens |

**Cost per query:**
- Input: 1,500 tokens × $0.10/1M = **$0.00015**
- Output: 350 tokens × $0.40/1M = **$0.00014**
- **Total: ~$0.0003 per query** (0.03 cents)

**Monthly cost projections:**

| Queries/Week | Monthly Cost |
|--------------|--------------|
| 500 | ~$0.60 |
| 1,000 | ~$1.20 |
| 5,000 | ~$6.00 |
| 10,000 | ~$12.00 |

**Conclusion:** Paid tier is extremely affordable. At current usage (~30 requests/day), monthly cost would be **less than $0.50**.

### Solution Implemented

#### 1. Error Classification

Added logic to distinguish between:
- **Rate limit (retryable):** Temporary, usually includes "retry in Xs" message
- **Quota exhausted (not retryable):** `limit: 0` indicates hard cap reached

**File:** `backend/app/utils/errors.py`

```python
class ErrorMessages:
    # Gemini API関連
    GEMINI_RATE_LIMITED = "リクエストが多すぎます。少々お待ちください。"
    GEMINI_QUOTA_EXHAUSTED = "APIの利用枠を超えました。管理者にお問い合わせください。"
    GEMINI_API_ERROR = "AIサービスでエラーが発生しました。"

class GeminiAPIException(RAGException):
    def __init__(self, message: str, code: str, is_retryable: bool = False, retry_after: float | None = None):
        super().__init__(message, code)
        self.is_retryable = is_retryable
        self.retry_after = retry_after
```

#### 2. Error Classification Helper

**File:** `backend/app/services/rag_service.py`

```python
def classify_gemini_error(error: Exception) -> GeminiAPIException:
    error_str = str(error)

    if isinstance(error, ResourceExhausted):
        # limit: 0 means quota exhausted - don't retry
        if "limit: 0" in error_str:
            return GeminiAPIException(
                ErrorMessages.GEMINI_QUOTA_EXHAUSTED,
                "QUOTA_EXHAUSTED",
                is_retryable=False,
            )

        # Extract retry time if available
        retry_match = re.search(r"retry in (\d+\.?\d*)s", error_str, re.IGNORECASE)
        retry_after = float(retry_match.group(1)) if retry_match else None

        return GeminiAPIException(
            ErrorMessages.GEMINI_RATE_LIMITED,
            "RATE_LIMITED",
            is_retryable=True,
            retry_after=retry_after,
        )

    return GeminiAPIException(
        ErrorMessages.GEMINI_API_ERROR,
        "GEMINI_ERROR",
        is_retryable=False,
    )
```

#### 3. Smart Retry Logic

Added retry with exponential backoff for transient rate limits only:

**File:** `backend/app/services/rag_service.py`

```python
async def run_chain():
    max_retries = 2
    base_delay = 2.0

    for attempt in range(max_retries + 1):
        try:
            await asyncio.to_thread(chain.invoke, {...})
            break  # Success
        except ResourceExhausted as e:
            gemini_error = classify_gemini_error(e)

            if not gemini_error.is_retryable or attempt == max_retries:
                await queue.put({
                    "type": "error",
                    "data": {"message": gemini_error.message, "code": gemini_error.code},
                })
                break

            # Retryable - wait and retry
            delay = gemini_error.retry_after or (base_delay * (2 ** attempt))
            await asyncio.sleep(delay)
        except Exception as e:
            await queue.put({
                "type": "error",
                "data": {"message": ErrorMessages.LLM_ERROR, "code": "LLM_ERROR"},
            })
            break

    await queue.put(None)  # End signal
```

**Retry behavior:**
- Max 2 retries for transient rate limits
- Uses `retry_after` from Gemini response if available
- Falls back to exponential backoff (2s, 4s)
- **No retry** for quota exhausted (`limit: 0`)

#### 4. Global Rate Limiter

Added a global rate limiter to prevent multiple users from collectively exceeding Gemini's limit:

**File:** `backend/app/utils/rate_limiter.py`

```python
class GlobalRateLimiter:
    """全ユーザー共通のレート制限（APIキー全体の使用量を制限）"""

    def __init__(self, requests_per_minute: int = 10):
        self.requests_per_minute = requests_per_minute
        self.requests: list[float] = []
        self._lock = Lock()

    def check_limit(self) -> bool:
        now = time.time()
        minute_ago = now - 60

        with self._lock:
            self.requests = [t for t in self.requests if t > minute_ago]
            if len(self.requests) >= self.requests_per_minute:
                return False
            self.requests.append(now)
            return True
```

**File:** `backend/app/config.py`

```python
# Rate Limiting
requests_per_minute: int = 15  # Per-IP limit
global_requests_per_minute: int = 10  # Global limit for Gemini free tier
```

#### 5. Chat Router Updates

**File:** `backend/app/routers/chat.py`

```python
# Check global limit first (protects Gemini API key)
if not global_rate_limiter.check_limit():
    # Return GLOBAL_RATE_LIMIT_EXCEEDED error
    ...

# Then check per-IP limit (prevents single user abuse)
if not rate_limiter.check_limit(client_ip):
    # Return RATE_LIMIT_EXCEEDED error
    ...
```

#### 6. Frontend Error Handling

**File:** `frontend/lib/constants.ts`

```typescript
export const ERROR_CODE_MESSAGES: Record<string, string> = {
  RATE_LIMITED: UI_TEXT.geminiRateLimited,
  QUOTA_EXHAUSTED: UI_TEXT.quotaExhausted,
  RATE_LIMIT_EXCEEDED: UI_TEXT.rateLimitError,
  GLOBAL_RATE_LIMIT_EXCEEDED: UI_TEXT.rateLimitError,
  GEMINI_ERROR: UI_TEXT.serverError,
  LLM_ERROR: UI_TEXT.serverError,
  INTERNAL_ERROR: UI_TEXT.serverError,
};
```

**File:** `frontend/hooks/useChat.ts`

```typescript
case "error": {
  const errorCode = event.data.code;
  const errorMessage = errorCode && ERROR_CODE_MESSAGES[errorCode]
    ? ERROR_CODE_MESSAGES[errorCode]
    : event.data.message;
  setError(errorMessage);
  // ...
}
```

### Files Modified

| File | Changes |
|------|---------|
| `backend/app/utils/errors.py` | Added `GEMINI_RATE_LIMITED`, `GEMINI_QUOTA_EXHAUSTED`, `GEMINI_API_ERROR` messages; Added `GeminiAPIException` class |
| `backend/app/services/rag_service.py` | Added `classify_gemini_error()` function; Added retry logic with exponential backoff |
| `backend/app/utils/rate_limiter.py` | Added `GlobalRateLimiter` class |
| `backend/app/config.py` | Added `global_requests_per_minute` setting |
| `backend/app/routers/chat.py` | Added global rate limit check before per-IP check |
| `frontend/lib/constants.ts` | Added error messages and `ERROR_CODE_MESSAGES` mapping |
| `frontend/hooks/useChat.ts` | Updated error handling to use error code mapping |

### Key Takeaways

1. **Rate Limit vs Quota:** These are different concepts. Rate limits are per-minute caps that reset; quotas are total usage limits.

2. **`limit: 0` Detection:** When Gemini returns `limit: 0`, it means the quota is exhausted. Don't retry - it will fail again.

3. **Global vs Per-IP Limiting:** For shared API keys, need both:
   - Global limit to protect the API key
   - Per-IP limit to prevent single user abuse

4. **User Feedback:** Silent failures are bad UX. Always show meaningful error messages.

5. **Retry Strategy:** Only retry transient errors. Use exponential backoff with jitter for production systems.

### Future Improvements

- [ ] Add usage monitoring/alerting when approaching quota limits
- [ ] Consider caching common queries to reduce API calls
- [ ] Add request queuing for smoother rate limiting experience
- [ ] Implement graceful degradation (e.g., suggest similar cached answers)
