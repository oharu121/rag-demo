# Dev Notes - 2025-12-18

## Problem: Evaluation Tests Too Easy

### What We Observed
- Raw dataset + simple chunking strategy passed 90%+ of evaluation tests
- This undermines the demo's goal: proving that **data quality matters more than LLM optimization**
- Initial test set (`test_queries_light.json`) had only 4 queries - too few to differentiate

### Root Cause Analysis
1. **General queries are too easy** - Questions like "通勤手当の上限額は？" have answers in plain sight in the documents
2. **Exception cases are the real differentiator** - Questions about part-timers (アルバイト, パート) require finding 附則 (supplementary provisions) which are harder to retrieve
3. **Term matching was too strict** - Answers using different but correct phrasing (e.g., "認められていません" vs "できない") were marked as failures

### What We Changed

#### 1. Created Hard Test File (`test_queries_hard.json`)
- **10 exception-only queries** - all test edge cases for part-timers
- Topics covered: 通勤手当, 休暇, 経費, リモートワーク, 福利厚生, 服務
- Each query tests whether RAG can find:
  - Different rules for アルバイト vs 正社員
  - Specific limits (e.g., 2万円 vs 5万円)
  - Prohibited actions for certain employee types

#### 2. Added More Expected Term Variations
Before:
```json
"expected_answer_contains": ["認められない", "できない", "対象外"]
```

After:
```json
"expected_answer_contains": [
  "認められない", "できない", "対象外",
  "認められていません", "できません", "取得できません",
  "適用されません", "許可されていません"
]
```

#### 3. Improved Failure Feedback (`ScoringAnnotation.tsx`)
- Shows expected terms when test fails: `期待: 「term1」「term2」「term3」など`
- Shows prohibited terms if incorrectly found: `誤検出: term1, term2`
- Helps debug why tests fail

#### 4. Simplified Test Selection
- Removed test difficulty selector from UI
- Always runs hard test - simpler UX, clearer differentiation

### Files Modified
- `backend/app/config.py` - Changed to use `test_queries_hard.json`
- `backend/app/data/evaluation/test_queries_hard.json` - NEW: 10 exception queries
- `backend/app/data/evaluation/test_queries_medium.json` - Added term variations
- `frontend/app/components/ScoringAnnotation.tsx` - Shows expected terms on failure

### Expected Outcome
With harder exception-only queries:
- **Raw dataset**: Should score lower (附則 scattered, harder to retrieve)
- **Optimized dataset**: Should score higher (exceptions better structured)

This better demonstrates that data quality and structure matter more than chunking strategy alone.

---

## Streaming Evaluation Implementation

### Problem
- User had to wait 30-60 seconds for all results to appear at once
- Poor UX - no feedback during evaluation

### Solution
Implemented token-by-token streaming for evaluation (like regular chat):

#### Backend (`evaluation.py`)
- New SSE endpoint: `GET /api/evaluate/stream`
- Event types:
  - `query_start` - question about to be asked
  - `token` - answer token (streamed)
  - `query_done` - scoring for completed query
  - `complete` - final score summary

#### Frontend
- `api.ts`: Added `streamEvaluation()` async generator
- `useChat.ts`: Added streaming evaluation methods
- `ChatInterface.tsx`: Handles streaming events, shows progress

### Result
- Questions and answers appear one by one as they're processed
- Real-time token streaming for each answer
- Progress indicator shows "Testing 3/10..."
- Much better UX

---

## Evaluation Logs Not Showing in Hugging Face Spaces

### Problem
After deploying to HF Spaces, evaluation logs were not appearing in the container logs. Only HTTP request logs were visible:
```
INFO:     10.16.9.169:23145 - "GET /api/evaluate/stream?document_set=original&strategy=standard HTTP/1.1" 200 OK
```

No details about which questions were being asked, what answers were generated, or scoring results.

### Root Cause
Python's `logging.getLogger(__name__)` creates a logger but **doesn't attach handlers by default**. In containerized environments like Hugging Face Spaces, only `print()` statements with `flush=True` go to the visible container logs.

The code had:
```python
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Later in code...
logger.info(f"[Evaluation Stream] Q: {question}")  # NOT visible in HF logs!
```

The `/quick` endpoint had both `logger.info()` AND `print()` statements (so it worked), but the `/stream` endpoint only had `logger.info()` calls.

### Fix
Changed all `logger.info()` / `logger.error()` calls in the streaming endpoint to `print(..., flush=True)`:

```python
# Before (not visible in HF Spaces)
logger.info(f"[Evaluation Stream] Q: {question}")

# After (visible in HF Spaces)
print(f"[Eval {index+1}/{total}] Q: {question}", flush=True)
```

### Log Output Format
After the fix, logs now show:
```
[Eval] Starting evaluation: document_set=original, strategy=standard
[Eval] Loaded 10 test queries
[Eval 1/10] Q: アルバイトの通勤手当の申請方法を教えてください。
[Eval 1/10] A: アルバイトの通勤手当は紙の「通勤届（短期雇用者用）」を...
[Eval 1/10] ✓ found=['紙', '店舗責任者'] | missing=[] | prohibited=[]
[Eval 2/10] Q: アルバイトの通勤手当の上限額はいくらですか？
...
[Eval] Complete: 7/10 (70%)
```

### Key Takeaway
**In Docker/containerized environments, always use `print(..., flush=True)` for logs that need to be visible.** Python's logging module requires explicit handler configuration to output to stdout, which may not be set up by default in container environments.

### File Modified
- `backend/app/routers/evaluation.py` - Changed `logger.info()` to `print(..., flush=True)`

---

## Research: Real-World RAG Failure Scenarios

### Why Current Tests Are Too Easy

Our current documents are **too well-structured** for realistic RAG testing:

1. **Exceptions are explicitly labeled** - Headers like "附則第3条（アルバイト・臨時スタッフに関する特則）"
2. **Topic keywords are repeated** - Exception sections re-state "通勤手当", "申請方法" etc.
3. **Documents are small** - Even naive chunking captures related information
4. **Strong keyword match** - Query "アルバイトの通勤手当" easily matches chunk with both keywords

The RAG succeeds because semantic similarity is high between query and exception chunk.

### Real RAG Failure Scenarios (from Research)

Based on research from [IBM](https://www.ibm.com/think/insights/rag-problems-five-ways-to-fix), [LAC Watch](https://www.lac.co.jp/lacwatch/people/20240118_003651.html), [Enterprise RAG Challenge](https://github.com/trustbit/enterprise-rag-challenge), and [生成AI社内活用ナビ](https://officebot.jp/columns/basic-knowledge/rag-assignment/):

#### 1. Distant Chunk with Implicit Reference (課題シナリオの核心)
- Long irrelevant text separates general rule from exception
- Exception doesn't re-state the topic ("ただし、短期雇用者は△△" without "通勤手当")
- RAG retrieves general rule chunk, misses distant implicit exception

#### 2. Multi-hop Reasoning
Requires finding and combining information from multiple locations:
- "アルバイトの結婚祝金と出産祝金の合計はいくら？"
- "正社員とアルバイトの結婚祝金の差額は？"
- IBM notes: RAG "cannot discern connections between entities"

#### 3. Negation Understanding
Questions about what is NOT allowed:
- "アルバイトが申請できない福利厚生は何？"
- "パートタイムに適用されない制度を教えて"
- Requires understanding exclusions, not just finding matches

#### 4. Information NOT in Documents (Hallucination Test)
Should answer "該当情報なし" but often hallucinates:
- "アルバイトの退職金はいくら？" (not in any document)
- Enterprise RAG Challenge: "Systems must respond 'N/A' rather than fabricating information"

#### 5. Aggregation Queries
Summing or counting across chunks:
- "アルバイトが受けられる福利厚生の総額は？"
- IBM: "Vector databases lack built-in aggregation functions"

#### 6. Conditional Logic
Specific conditions buried in documents:
- "勤続6ヶ月のアルバイトは結婚祝金をもらえる？" (requires 1年以上)
- "週15時間勤務のパートは健康診断を受けられる？" (requires 20時間以上)

#### 7. Cross-document Queries
Information spans multiple files:
- "アルバイトが経費精算と慶弔見舞金の両方を申請する手続きは？"
- Requires retrieving from 経費精算規程.md AND 福利厚生規程.md

#### 8. Conflicting/Versioned Information
When multiple rules could apply:
- Old vs new policy versions
- General rule vs specific exception

### Key Research Insights

From LAC Watch (社内規程集RAG評価):
> 「1,000文字で分割した文書では Retrieval Correctness が最低の3.75となり、250文字程度に分割した方が良い結果となった」

From IBM:
> "Pure RAG is not really giving the optimal results that were expected... you don't know where you're chunking the data...you chunked in the middle of a table"

From 生成AI社内活用ナビ:
> 「企業が業務で利用している資料は、図表が多く含まれていたり、ページ数も多く複雑です」

---

## Next Plan: Dataset Restructuring

### Current Problem with Our Documents

Our "raw" documents in `regulations/` are actually well-structured:

```markdown
### 附則第3条（アルバイト・臨時スタッフに関する特則）  ← Explicit header!
アルバイトおよび臨時スタッフの通勤手当については、以下のとおり...  ← Re-states topic!
1. 申請方法は紙の届出書を使用...  ← Clearly numbered!
```

**Why RAG succeeds:**
- Query: "アルバイトの通勤手当の申請方法"
- Chunk contains: "アルバイト" + "通勤手当" + "申請" → Strong semantic match
- Result: Easy retrieval, correct answer

### What the Real Problem Looks Like

The challenge scenario describes realistic enterprise documents:

```markdown
第5条（申請方法）
従業員は、HR Portalから通勤届を提出する。届出は入社時および届出内容に
変更が生じた場合に行う...

第6条（支給額の計算）
通勤手当の支給額は、住居から勤務地までの最も経済的かつ合理的な経路に
基づき算定する。算定にあたっては、以下の基準を適用する...
[... 500 characters of calculation methods ...]

第7条（届出内容の変更）
届出内容に変更が生じた場合は、変更が生じた日から14日以内に届け出る
こととする。届出を怠った場合は...
[... 300 characters of change procedures ...]

第8条（届出の特例）
第5条の規定にかかわらず、短期雇用者については所定の届出書を
店舗責任者に提出する。届出書の様式は別紙のとおりとする。
```

**Why RAG fails:**
- Query: "アルバイトの通勤手当の申請方法"
- 第5条 chunk: "申請方法" + "届出" → Retrieved (wrong answer)
- 第8条 chunk: "短期雇用者" + "届出書" → NOT retrieved (no "通勤手当", no "申請")
- Result: Returns general rule, misses exception

### Strategy for Raw Dataset (`regulations/`)

#### 1. Bury exceptions in non-obvious sections
- Move from "附則（アルバイト特則）" to "第X条（届出の特例）" or "第X条（雑則）"
- Don't use employee type in section header

#### 2. Add long filler between general rule and exception
- Calculation methods, approval flows, change procedures
- Target: 500-1000 characters between related content
- Forces chunking to split general rule from exception

#### 3. Make exceptions implicit (no topic keyword repetition)
- ❌ Current: "アルバイトの通勤手当の申請は紙で行う"
- ✅ Realistic: "第5条の規定にかかわらず、短期雇用者については所定の届出書を使用する"
- Uses "前条", "第X条の規定にかかわらず" instead of restating topic

#### 4. Use indirect employee type references
- ❌ Current: "アルバイトおよび臨時スタッフ"
- ✅ Realistic: "短期雇用者", "非正規従業員", "第2条第3項に定める者"

### Strategy for Optimized Dataset (`regulations-optimized/`)

Keep well-structured with:
- Explicit headers: "## アルバイトの通勤手当"
- Q&A format where applicable
- Topic keywords repeated in each section
- Cross-references made explicit

### Expected Evaluation Results

| Dataset | Strategy | Expected Score | Reason |
|---------|----------|----------------|--------|
| Raw (restructured) | Standard | 30-50% | Can't find implicit exceptions |
| Raw (restructured) | Parent-child | 50-70% | Captures more context |
| Optimized | Standard | 80-90% | Explicit structure |
| Optimized | Parent-child | 85-95% | Best of both |

### New Test Query Categories

| Category | Example Query | Why It's Hard |
|----------|---------------|---------------|
| **Distant implicit** | アルバイトの通勤手当の申請方法は？ | Exception buried, no topic keyword |
| **Multi-hop** | 結婚祝金と出産祝金の合計は？ | Needs 2 retrievals + calculation |
| **Comparison** | 正社員とアルバイトの差額は？ | Needs 2 retrievals + comparison |
| **Negation** | 申請できない福利厚生は？ | Understanding exclusions |
| **Not in docs** | アルバイトの退職金は？ | Should say "規定なし" |
| **Conditional** | 勤続6ヶ月で結婚祝金もらえる？ | Specific condition check |
| **Cross-document** | 経費と慶弔の両方の申請手続きは？ | Multiple file retrieval |

### Files to Modify

1. `backend/app/data/regulations/*.md` - Restructure to realistic pattern
2. `backend/app/data/evaluation/test_queries_hard.json` - Add new query categories
3. Keep `backend/app/data/regulations-optimized/*.md` - Well-structured (the "solution")

---

## Dataset Restructuring Complete

### Changes Applied to All 6 Regulation Files

**Pattern Changes:**
1. **Exceptions moved from explicit headers** (`附則（アルバイト特則）`) **to implicit sections** (`第X条（〇〇の特例）`)
2. **Used indirect employee references**: `第2条の2に定める者`, `短期雇用者` instead of `アルバイト`
3. **Added filler text** between general rules and exceptions (approval flows, calculation methods, etc.)
4. **Removed topic keyword repetition** in exception sections

**Files Modified:**
- `通勤手当規程.md` - Exceptions now in 第11条-13条
- `休暇規程.md` - Exceptions in 第12条-15条
- `経費精算規程.md` - Exceptions in 第16条-20条
- `福利厚生規程.md` - Exceptions in 第17条-24条
- `リモートワーク規程.md` - Exceptions in 第16条-20条
- `服務規程.md` - Exceptions in 第16条-21条

### Test Queries Updated

`test_queries_hard.json` now has **15 queries** in 6 categories:

| Category | Count | Description |
|----------|-------|-------------|
| `implicit_exception` | 5 | Exceptions buried with indirect references |
| `multi_hop` | 2 | Requires combining info from multiple locations |
| `negation` | 2 | Questions about what is NOT allowed |
| `conditional` | 2 | Specific condition checks (e.g., "勤続6ヶ月で...") |
| `not_in_documents` | 2 | Hallucination tests (退職金, ボーナス) |
| `cross_document` | 2 | Information spanning multiple files |

---

## Evaluation Results Analysis

### Raw Scores by Strategy

| Strategy | Raw Score | Pass Rate |
|----------|-----------|-----------|
| Standard (1000/200) | 9/15 | 60% |
| **Large (2000/500)** | **12/15** | **80%** |
| Parent-child | 10/15 | 67% |

### Adjusted Analysis (with term fixes)

After adding "含まれていません" to expected terms for not_in_documents queries:

| Strategy | Current | After Term Fix | After Context-Aware Scoring |
|----------|---------|----------------|----------------------------|
| Standard | 9/15 (60%) | 11/15 (73%) | ~12/15 (80%) |
| Large | 12/15 (80%) | 14/15 (93%) | ~14/15 (93%) |
| Parent-child | 10/15 (67%) | 12/15 (80%) | **15/15 (100%)** |

### Why Parent-Child Appears to Underperform

Looking at the failures, there's a consistent pattern:

#### Problem 1: Parent-child retrieves MORE context, including contradictory info

**Query 1 & 14** - Both failed with `prohibited=['オンラインシステム']`

The parent-child approach retrieves the **parent chunk** which contains BOTH:
- The general rule: "申請は、オンラインシステム「HR Portal」から行う"
- The exception: "第2条の2に定める短期雇用者については、所定の届出書を店舗責任者に提出"

The LLM then **mentions both** in its answer to provide complete context, triggering the prohibited term check.

**Large chunk** doesn't have this problem because it retrieves a more focused section.

#### Problem 2: Query 4 - Parent brings in パートタイム rules too

```
[Eval 4/15] ✗ found=['交通費'] | missing=[] | prohibited=['接待交際費', '出張', '消耗品']
```

Parent-child retrieved a chunk that included:
> "週の所定労働日数が3日以下のパートタイム従業員については、精算対象経費は交通費および**消耗品費**に限ります"

The LLM mentioned "消耗品" in context of パートタイム (different employee type), and mentioned "接待交際費、出張旅費は認められません" (negation context). Our prohibited check doesn't distinguish context - it just looks for the word.

#### Root Cause

**Parent-child's design characteristic for this use case:**

1. **Child chunk** matches query well (exception section)
2. **Parent chunk** is retrieved, which includes general rules + exception
3. LLM sees both and **explains both** in the answer for completeness
4. Our scoring penalizes mentioning prohibited terms **regardless of context**

**Large chunk wins in raw scoring because:**
- 2000 char chunks are big enough to capture exception context
- But not so big that they include the general rule section
- Result: cleaner answers without prohibited terms

### Parent-Child Scoring Analysis (Fair Assessment)

| # | Query | Current Result | Should Be | Reason |
|---|-------|----------------|-----------|--------|
| 1 | 通勤手当の申請方法 | ✗ | ✓ | Found correct answer. Mentioned "オンラインシステム" only to explain it's NOT available |
| 2 | 通勤手当の上限額 | ✓ | ✓ | Correct |
| 3 | 結婚休暇 | ✓ | ✓ | Correct |
| 4 | 経費精算項目 | ✗ | ✓ | Found "交通費のみ". Mentioned "消耗品" for パートタイム (different type), "接待交際費は認められません" (negation) |
| 5 | リモートワーク | ✓ | ✓ | Correct |
| 6 | 結婚祝金の差額 | ✓ | ✓ | Correct |
| 7 | 通勤手当上限の差額 | ✓ | ✓ | Correct |
| 8 | 利用できない福利厚生 | ✓ | ✓ | Correct |
| 9 | 経費精算できない項目 | ✓ | ✓ | Correct |
| 10 | 勤続6ヶ月で結婚祝金 | ✓ | ✓ | Correct |
| 11 | 入社8ヶ月でリモート | ✓ | ✓ | Correct |
| 12 | 退職金 | ✗ | ✓ | Said "含まれていません" - term now in expected list |
| 13 | ボーナス | ✗ | ✓ | Said "含まれていません" - term now in expected list |
| 14 | 各種届出は紙か | ✗ | ✓ | Found "紙", "店舗責任者". Mentioned "オンラインシステム" to contrast what アルバイト can't use |
| 15 | 金銭的支援項目 | ✓ | ✓ | Correct |

**Fair Score for Parent-Child: 15/15 (100%)**

Parent-child is actually giving **complete, accurate answers** that explain both what applies and what doesn't. The scoring logic is too simplistic to recognize this.

### Key Insight

The prohibited term check is fundamentally flawed for comprehensive answers:

```
# Current logic (too simplistic)
if any(term in answer for term in prohibited_terms):
    return FAIL

# What we need (context-aware)
if any(term in answer AND term is presented as correct/applicable):
    return FAIL
```

Examples of false negatives:
- "アルバイトはオンラインシステムを**利用できません**" → Marked as fail (mentions オンラインシステム)
- "消耗品費は**認められません**" → Marked as fail (mentions 消耗品)

### Recommendations

#### Option A: Fix the scoring logic
Don't mark as failed if prohibited terms appear in a **negation context** like:
- "〇〇は利用できません"
- "〇〇は認められません"
- "〇〇は対象外です"

#### Option B: Remove prohibited term checks
For questions where explaining "X instead of Y" is valuable, just verify correct answer is present:
```json
"expected_answer_must_not_contain": []  // Remove prohibited checks
```

#### Option C: Accept current results as meaningful
The results still demonstrate something valuable:
- **Large chunk (80%)** > Parent-child (67%) > Standard (60%)
- This shows chunking strategy matters for **simpler scoring metrics**
- Parent-child actually produces **better quality answers** but scores lower due to metric limitations

### Conclusion

Parent-child is the **best strategy** for answer quality - it provides the most complete and contextual responses. However, our current scoring metric penalizes completeness. This is a metric problem, not a strategy problem.

---

## Changes Applied (2025-12-18 - Final)

### 1. Removed Prohibited Term Checks from `test_queries_hard.json`

**Rationale:** Option B selected - simpler and more realistic. Comprehensive answers that explain "X instead of Y" shouldn't be penalized.

**Change:** Removed all `expected_answer_must_not_contain` fields from all 15 queries.

Before:
```json
{
  "expected_answer_contains": ["届出書", "店舗責任者"],
  "expected_answer_must_not_contain": ["HR Portal", "オンラインシステム"]
}
```

After:
```json
{
  "expected_answer_contains": ["届出書", "店舗責任者"]
}
```

### 2. Made Raw Dataset Harder - Removed "アルバイト" from 短期雇用者 Definition

**Rationale:** The definition explicitly listed "アルバイト、臨時スタッフ、季節労働者等" which made keyword matching too easy.

**Change:** Updated all 6 regulation files to use an implicit definition:

Before:
```markdown
### 第2条の2（短期雇用者の定義）
本規程において「短期雇用者」とは、雇用期間が1年未満の者、または週の所定労働時間が30時間未満の者をいう。アルバイト、臨時スタッフ、季節労働者等がこれに該当する。
```

After:
```markdown
### 第2条の2（短期雇用者の定義）
本規程において「短期雇用者」とは、雇用期間が1年未満の者、または週の所定労働時間が30時間未満の者をいう。具体的な該当者については、人事部が個別に判断する。
```

**Files Modified:**
- `通勤手当規程.md`
- `休暇規程.md`
- `経費精算規程.md`
- `福利厚生規程.md`
- `リモートワーク規程.md`
- `服務規程.md`

### Expected Impact

| Before Changes | After Changes |
|----------------|---------------|
| Easy keyword match: "アルバイト" appears in 短期雇用者 definition | No direct "アルバイト" mention - requires understanding that 短期雇用者 = アルバイト |
| Parent-child penalized for comprehensive answers | Parent-child can explain context without penalty |
| Strategies harder to differentiate | Clearer differentiation based on retrieval quality |

### Next Step

Re-run evaluation to verify:
1. Raw dataset scores lower (no "アルバイト" keyword match)
2. Parent-child scores higher (no prohibited term penalties)
3. Different strategies show clearer differentiation
